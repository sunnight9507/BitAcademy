{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#필요 라이브러리 임포트\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# interactive graph\n",
    "import plotly.graph_objects as go\n",
    "import cufflinks as cf \n",
    "import plotly.express as px\n",
    "cf.go_offline(connected=True)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import platform\n",
    "path = 'c:/Windows/Fonts/malgun.ttf'\n",
    "from matplotlib import font_manager, rc\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print('Unknown system... sorry~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_train = pd.read_csv('data/train.csv')\n",
    "titanic_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_train.shape)\n",
    "titanic_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 12개의 column을 가지고 있고 전체 891개의 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.bar(titanic_train,title = 'feature 별 null 값 갯수', x=titanic_train.isnull().sum().sort_values(ascending = False).index, y=titanic_train.isnull().sum().sort_values(ascending = False), text = titanic_train.isnull().sum().sort_values(ascending = False),height= 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  **null 값의 개수** : Cabin은 약 700개, Age는 180개의 null값을 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(titanic_train,title = '생존자 비율 확인', x=[0,1], y=titanic_train['Survived'].value_counts() / len(titanic_train), text = (titanic_train['Survived'].value_counts() / len(titanic_train)).round(2), color=titanic_train['Survived'].value_counts(),color_continuous_scale=['green','red'],width=600, height= 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "data = titanic_train.groupby(['Sex','Survived'])['Survived'].count()\n",
    "labels = [\"Survived = 0\", \"Survived = 1\"]\n",
    "\n",
    "# Create subplots: use 'domain' type for Pie subplot\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "fig.add_trace(go.Pie(labels=labels, values=[data[2], data[3]], name=\"male\", marker_colors = [\"red\",\"green\"]),1, 1)\n",
    "fig.add_trace(go.Pie(labels=labels, values=[data[0], data[1]], name=\"female\"),1, 2)\n",
    "\n",
    "fig.update_traces(hole=.4)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"성별에 따른 생존자 비율\",\n",
    "    annotations=[dict(text='Male', x=0.19, y=0.5, font_size=20, showarrow=False),\n",
    "                 dict(text='Female', x=0.83, y=0.5, font_size=20, showarrow=False)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 별 생존자 확인\n",
    "sns.catplot(x='Survived', col='Embarked', kind='count', data=titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이, 성별 별 생존자 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(titanic_train['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare(data):\n",
    "    if data['Age'] == 0:\n",
    "        if data.Embarked == 'C':\n",
    "            if data.Pclass == 1:\n",
    "                return 36.5\n",
    "            elif data.Pclass == 2:\n",
    "                return 25\n",
    "            else:\n",
    "                return 20\n",
    "        elif data.Embarked == 'S':\n",
    "            if data.Pclass == 1:\n",
    "                return 37\n",
    "            elif data.Pclass == 2:\n",
    "                return 30\n",
    "            else:\n",
    "                return 25\n",
    "        else:\n",
    "            # Q에 대한 인원이 많지 않아 하나로 통합\n",
    "            return 27\n",
    "    else:\n",
    "        return data['Age']\n",
    "    \n",
    "def func(age):\n",
    "    if age <= 2: return 1\n",
    "    elif age <= 5: return 2\n",
    "    elif age <= 10: return 3\n",
    "    elif age <= 18: return 4\n",
    "    elif age <= 25: return 5\n",
    "    elif age <= 40: return 6\n",
    "    elif age <= 60: return 7\n",
    "    else : return 8\n",
    "\n",
    "# 0.8339\n",
    "def data_processing(data):\n",
    "    # index 설정\n",
    "    data = data.set_index('PassengerId')\n",
    "    \n",
    "    # column 제거\n",
    "    data.drop(['Name', 'Ticket'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Embarked, Cabin null 값 변경\n",
    "    data['Embarked'].fillna('N',inplace=True)\n",
    "    data['Cabin'].fillna('N',inplace=True)\n",
    "    \n",
    "    # Age의 nan 값 변경 / Embarked, Pclass 별로 중앙값으로 대체\n",
    "    data['Age'].fillna(0, inplace=True)\n",
    "    data['new_Age'] = data[['Embarked', 'Pclass', 'Age']].apply(fare, axis = 1)\n",
    "    data.drop(['Age'], axis = 1, inplace = True)\n",
    "    \n",
    "    data['Age'] = data.new_Age.apply(func)\n",
    "    data.drop(['new_Age'], axis = 1, inplace = True)\n",
    "    \n",
    "    data['Cabin'] = data.Cabin.apply(lambda x: x[0])\n",
    "    data = pd.concat([data, pd.get_dummies(data[['Embarked', 'Sex','Cabin']])], axis = 1)\n",
    "    data.drop(['Embarked', 'Sex','Cabin'], axis = 1, inplace = True)\n",
    "    \n",
    "    # data.drop(['Pclass', 'Sex', 'Embarked', 'Age'], axis = 1, inplace = True)\n",
    "    \n",
    "    # data['Sex'] = LabelEncoder().fit(data['Sex']).transform(data['Sex'])\n",
    "    #data['Embarked'] = LabelEncoder().fit(data['Embarked']).transform(data['Embarked'])\n",
    "    \n",
    "    # data['Age'] = LabelEncoder().fit(data['Age']).transform(data['Age'])\n",
    "    \n",
    "    # test set의 Fare null 값 대체\n",
    "    data.Fare.fillna(data['Fare'].median(), inplace = True)\n",
    "    \n",
    "    # minmax_scale 적용\n",
    "    data['Fare'] = minmax_scale(data.Fare)\n",
    "    data['Age'] = minmax_scale(data.Age)\n",
    "    #data['SibSp'] = minmax_scale(data.SibSp)\n",
    "    #data['Parch'] = minmax_scale(data.Parch)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8328\n",
    "def data_processing(data):\n",
    "    # index 설정\n",
    "    data = data.set_index('PassengerId')\n",
    "    \n",
    "    # column 제거\n",
    "    data.drop(['Name', 'Ticket','Cabin'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Embarked, Cabin null 값 변경\n",
    "    data['Embarked'].fillna('N',inplace=True)\n",
    "    # data['Cabin'].fillna('N',inplace=True)\n",
    "    \n",
    "    # Age의 nan 값 변경 / Embarked, Pclass 별로 중앙값으로 대체\n",
    "    data['Age'].fillna(0, inplace=True)\n",
    "    data['new_Age'] = data[['Embarked', 'Pclass', 'Age']].apply(fare, axis = 1)\n",
    "    data.drop(['Age'], axis = 1, inplace = True)\n",
    "    \n",
    "    data['Age'] = data.new_Age.apply(func)\n",
    "    data.drop(['new_Age'], axis = 1, inplace = True)\n",
    "    \n",
    "    # data['Cabin'] = data.Cabin.apply(lambda x: x[0])\n",
    "    data = pd.concat([data, pd.get_dummies(data[['Embarked', 'Sex']])], axis = 1)\n",
    "    data.drop(['Embarked', 'Sex'], axis = 1, inplace = True)\n",
    "    \n",
    "    # data.drop(['Pclass', 'Sex', 'Embarked', 'Age'], axis = 1, inplace = True)\n",
    "    \n",
    "    # data['Sex'] = LabelEncoder().fit(data['Sex']).transform(data['Sex'])\n",
    "    #data['Embarked'] = LabelEncoder().fit(data['Embarked']).transform(data['Embarked'])\n",
    "    \n",
    "    # data['Age'] = LabelEncoder().fit(data['Age']).transform(data['Age'])\n",
    "    \n",
    "    # test set의 Fare null 값 대체\n",
    "    data.Fare.fillna(data['Fare'].median(), inplace = True)\n",
    "    \n",
    "    # minmax_scale 적용\n",
    "    data['Fare'] = minmax_scale(data.Fare)\n",
    "    data['Age'] = minmax_scale(data.Age)\n",
    "    #data['SibSp'] = minmax_scale(data.SibSp)\n",
    "    #data['Parch'] = minmax_scale(data.Parch)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Sex','Embarked','Cabin']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = titanic_train.copy()\n",
    "df = titanic_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = transform_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_processing(test)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "params = { 'max_depth':3,\n",
    "           'eta': 0.1,\n",
    "           'objective':'binary:logistic',\n",
    "           'eval_metric':'logloss',\n",
    "           'early_stoppings':100\n",
    "        }\n",
    "num_rounds = 400\n",
    "evals = [(X_test, y_test)]\n",
    "\n",
    "# 0.8328\n",
    "def data_analysis(data):\n",
    "    X_train, X_test, y_train, y_test=train_test_split(data.iloc[:,1:], data.iloc[:,0],random_state=10)\n",
    " \n",
    "    dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "    rf_clf = RandomForestClassifier(random_state=0)\n",
    "    lr_clf = LogisticRegression()\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=10)\n",
    "    gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "    \n",
    "    xgb_clf = XGBClassifier(n_estimators=300, learning_rate=0.01, max_depth=7)\n",
    "    \n",
    "    xgb_clf.fit(X_train , y_train, eval_metric=\"logloss\",  verbose=True)\n",
    "    pred = xgb_clf.predict(X_test)\n",
    "    print('{0} 정확도: {1:.4f}'.format(xgb_clf.__class__.__name__, accuracy_score(y_test , pred)))\n",
    "    \n",
    "    # voting : 0.87 / rf, xgb\n",
    "    vo_clf = VotingClassifier( estimators=[# ('dt',dt_clf),\n",
    "                                           # ('rf',rf_clf),\n",
    "                                           # ('lr',lr_clf),\n",
    "                                           # ('knn',knn_clf),\n",
    "                                           ('gb',gb_clf),\n",
    "                                           ('xgb',xgb_clf)]\n",
    "                              ,voting='soft')\n",
    "    vo_clf.fit(X_train , y_train)\n",
    "    pred = vo_clf.predict(X_test)\n",
    "    print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "    # 개별 모델의 학습/예측/평가.\n",
    "    classifiers = [dt_clf, rf_clf, lr_clf, knn_clf, gb_clf]\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(X_train , y_train)\n",
    "        pred = classifier.predict(X_test)\n",
    "        class_name= classifier.__class__.__name__\n",
    "        print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test, pred)))\n",
    "    \n",
    "    # result = rf_pred\n",
    "    print()\n",
    "    print()\n",
    "    # exec_kfold 호출\n",
    "    classifiers = [gb_clf, rf_clf, xgb_clf, vo_clf]\n",
    "    for classifier in classifiers:\n",
    "        print(classifier.__class__.__name__)\n",
    "        exec_kfold(classifier)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analysis(data):\n",
    "    X_train, X_test, y_train, y_test=train_test_split(data.iloc[:,1:], data.iloc[:,0],random_state=10)\n",
    " \n",
    "    dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "    rf_clf = RandomForestClassifier(random_state=0)\n",
    "    lr_clf = LogisticRegression()\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=21)\n",
    "    gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "    \n",
    "    xgb_clf = XGBClassifier(n_estimators=300, learning_rate=0.01, max_depth=7)\n",
    "    \n",
    "    xgb_clf.fit(X_train , y_train, eval_metric=\"logloss\",  verbose=True)\n",
    "    pred = xgb_clf.predict(X_test)\n",
    "    print('{0} 정확도: {1:.4f}'.format(xgb_clf.__class__.__name__, accuracy_score(y_test , pred)))\n",
    "    \n",
    "    # voting : 0.87 / rf, xgb\n",
    "    vo_clf = VotingClassifier( estimators=[# ('dt',dt_clf),\n",
    "                                           ('rf',rf_clf),\n",
    "                                           # ('lr',lr_clf),\n",
    "                                           # ('knn',knn_clf),\n",
    "                                           ('gb',gb_clf),\n",
    "                                           ('xgb',xgb_clf)]\n",
    "                              ,voting='soft')\n",
    "    vo_clf.fit(X_train , y_train)\n",
    "    pred = vo_clf.predict(X_test)\n",
    "    print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "    # 개별 모델의 학습/예측/평가.\n",
    "    classifiers = [dt_clf, rf_clf, lr_clf, knn_clf, gb_clf]\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(X_train , y_train)\n",
    "        pred = classifier.predict(X_test)\n",
    "        class_name= classifier.__class__.__name__\n",
    "        print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test, pred)))\n",
    "    \n",
    "    # result = rf_pred\n",
    "    print()\n",
    "    print()\n",
    "    # exec_kfold 호출\n",
    "    classifiers = [gb_clf, rf_clf, xgb_clf, vo_clf]\n",
    "    for classifier in classifiers:\n",
    "        print(classifier.__class__.__name__)\n",
    "        exec_kfold(data, classifier)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_kfold(data, clf, folds=7):\n",
    "    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "    # KFold 교차 검증 수행. \n",
    "    for iter_count , (train_index, test_index) in enumerate(kfold.split(data.iloc[:,1:])):\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train, X_test = data.iloc[:,1:].values[train_index], data.iloc[:,1:].values[test_index]\n",
    "        y_train, y_test = data.iloc[:,0].values[train_index], data.iloc[:,0].values[test_index]\n",
    "        \n",
    "        # Classifier 학습, 예측, 정확도 계산 \n",
    "        clf.fit(X_train, y_train) \n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "    # 5개 fold에서의 평균 정확도 계산. \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균 정확도: {0:.4f}\".format(mean_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#필요 라이브러리 임포트\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# interactive graph\n",
    "import plotly.graph_objects as go\n",
    "import cufflinks as cf \n",
    "import plotly.express as px\n",
    "cf.go_offline(connected=True)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import platform\n",
    "path = 'c:/Windows/Fonts/malgun.ttf'\n",
    "from matplotlib import font_manager, rc\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print('Unknown system... sorry~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8328\n",
    "def data_processing(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    \n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    \n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('data/train.csv')\n",
    "titanic_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived',axis=1)\n",
    "\n",
    "X_titanic_df = data_processing(X_titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "params = { 'max_depth':3,\n",
    "           'eta': 0.1,\n",
    "           'objective':'binary:logistic',\n",
    "           'eval_metric':'logloss',\n",
    "           'early_stoppings':100\n",
    "        }\n",
    "num_rounds = 400\n",
    "\n",
    "\n",
    "# 0.8328\n",
    "def data_analysis(data):\n",
    "    X_train, X_test, y_train, y_test=train_test_split(data.iloc[:,1:], data.iloc[:,0],random_state=10)\n",
    "    evals = [(X_test, y_test)]\n",
    " \n",
    "    dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "    rf_clf = RandomForestClassifier(random_state=0)\n",
    "    lr_clf = LogisticRegression()\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=10)\n",
    "    gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "    \n",
    "    xgb_clf = XGBClassifier(n_estimators=300, learning_rate=0.01, max_depth=7)\n",
    "    \n",
    "    xgb_clf.fit(X_train , y_train, eval_metric=\"logloss\",  verbose=True)\n",
    "    pred = xgb_clf.predict(X_test)\n",
    "    print('{0} 정확도: {1:.4f}'.format(xgb_clf.__class__.__name__, accuracy_score(y_test , pred)))\n",
    "    \n",
    "    # voting : 0.87 / rf, xgb\n",
    "    vo_clf = VotingClassifier( estimators=[('dt',dt_clf),\n",
    "                                           # ('rf',rf_clf),\n",
    "                                           # ('lr',lr_clf),\n",
    "                                           # ('knn',knn_clf),\n",
    "                                           ('gb',gb_clf),\n",
    "                                           ('xgb',xgb_clf)]\n",
    "                              ,voting='soft')\n",
    "    vo_clf.fit(X_train , y_train)\n",
    "    pred = vo_clf.predict(X_test)\n",
    "    print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "    # 개별 모델의 학습/예측/평가.\n",
    "    classifiers = [dt_clf, rf_clf, lr_clf, knn_clf, gb_clf]\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(X_train , y_train)\n",
    "        pred = classifier.predict(X_test)\n",
    "        class_name= classifier.__class__.__name__\n",
    "        print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test, pred)))\n",
    "    \n",
    "    # result = rf_pred\n",
    "    print()\n",
    "    print()\n",
    "    # exec_kfold 호출\n",
    "    classifiers = [gb_clf, rf_clf, xgb_clf, vo_clf]\n",
    "    for classifier in classifiers:\n",
    "        print(classifier.__class__.__name__)\n",
    "        exec_kfold(data, classifier)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_kfold(data, clf, folds=7):\n",
    "    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "    # KFold 교차 검증 수행. \n",
    "    for iter_count , (train_index, test_index) in enumerate(kfold.split(data.iloc[:,1:])):\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train, X_test = data.iloc[:,1:].values[train_index], data.iloc[:,1:].values[test_index]\n",
    "        y_train, y_test = data.iloc[:,0].values[train_index], data.iloc[:,0].values[test_index]\n",
    "        \n",
    "        # Classifier 학습, 예측, 정확도 계산 \n",
    "        clf.fit(X_train, y_train) \n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "    # 5개 fold에서의 평균 정확도 계산. \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균 정확도: {0:.4f}\".format(mean_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier 정확도: 0.9462\n",
      "Voting 분류기 정확도: 0.9507\n",
      "DecisionTreeClassifier 정확도: 0.9507\n",
      "RandomForestClassifier 정확도: 0.9372\n",
      "LogisticRegression 정확도: 0.8117\n",
      "KNeighborsClassifier 정확도: 0.8475\n",
      "GradientBoostingClassifier 정확도: 0.9552\n",
      "\n",
      "\n",
      "GradientBoostingClassifier\n",
      "교차 검증 0 정확도: 0.9688\n",
      "교차 검증 1 정확도: 0.9297\n",
      "교차 검증 2 정확도: 0.9685\n",
      "교차 검증 3 정확도: 0.9528\n",
      "교차 검증 4 정확도: 0.9528\n",
      "교차 검증 5 정확도: 0.9528\n",
      "교차 검증 6 정확도: 0.9370\n",
      "평균 정확도: 0.9517\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "교차 검증 0 정확도: 0.9375\n",
      "교차 검증 1 정확도: 0.9297\n",
      "교차 검증 2 정확도: 0.9528\n",
      "교차 검증 3 정확도: 0.8898\n",
      "교차 검증 4 정확도: 0.9291\n",
      "교차 검증 5 정확도: 0.9449\n",
      "교차 검증 6 정확도: 0.9055\n",
      "평균 정확도: 0.9270\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "교차 검증 0 정확도: 0.9531\n",
      "교차 검증 1 정확도: 0.9141\n",
      "교차 검증 2 정확도: 0.9606\n",
      "교차 검증 3 정확도: 0.9606\n",
      "교차 검증 4 정확도: 0.9370\n",
      "교차 검증 5 정확도: 0.9449\n",
      "교차 검증 6 정확도: 0.9134\n",
      "평균 정확도: 0.9405\n",
      "\n",
      "\n",
      "VotingClassifier\n",
      "교차 검증 0 정확도: 0.9453\n",
      "교차 검증 1 정확도: 0.9297\n",
      "교차 검증 2 정확도: 0.9528\n",
      "교차 검증 3 정확도: 0.9528\n",
      "교차 검증 4 정확도: 0.9449\n",
      "교차 검증 5 정확도: 0.9370\n",
      "교차 검증 6 정확도: 0.9213\n",
      "평균 정확도: 0.9405\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_analysis(X_titanic_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
